# -*- coding: utf-8 -*-
"""Training ESPEYE TFModel

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18NfNVv6EbJ6ttpuaRw_DrHYy35HDzwwW

## Setup
"""

import matplotlib.pylab as plt
import numpy as np
import PIL.Image as Image
import tensorflow as tf

!pip install tensorflow-hub
!pip install tensorflow-datasets
import tensorflow_hub as hub
from tensorflow.keras import layers

"""## Retraining top layer of model for our classes

### Mount Google Drive a/c to load dataset
**using train_celebs**
"""

from google.colab import drive
drive.mount('/content/drive')

"""**`ImageDataGenerator` rescales the image to float inputs between the `[0, 1]` range!**"""

IMAGE_SHAPE = (224, 224)
image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255)
train_data = image_generator.flow_from_directory(str('/content/drive/My Drive/train_celebs'), target_size=IMAGE_SHAPE)

test_data = image_generator.flow_from_directory(str('/content/drive/My Drive/test_celebs'), target_size=IMAGE_SHAPE)

"""The resulting object is an iterator that returns `image_batch, label_batch` pairs."""

for train_image_batch, label_batch in train_data:
  print("Image batch shape: ", train_image_batch.shape)
  print("Label batch shape: ", label_batch.shape)
  break

for test_image_batch, label_batch in test_data:
  print("Image batch shape: ", test_image_batch.shape)
  print("Label batch shape: ", label_batch.shape)
  break

"""### Download the headless model"""

feature_extractor_url = "https://tfhub.dev/tensorflow/efficientnet/lite0/feature-vector/2" #@param {type:"string"}

"""Create the feature extractor."""

feature_extractor_layer = hub.KerasLayer(feature_extractor_url,
                                         input_shape=(224,224,3))

"""It returns a 1280-length vector for each image:"""

train_feature_batch = feature_extractor_layer(train_image_batch)
print(train_feature_batch.shape)

test_feature_batch = feature_extractor_layer(test_image_batch)
print(test_feature_batch.shape)

"""Freeze the variables in the feature extractor layer, so that the training only modifies the new classifier layer."""

feature_extractor_layer.trainable = False

"""### Attach a classification head

Now wrap the hub layer in a `tf.keras.Sequential` model, and add a new classification layer.
"""

model = tf.keras.Sequential([
  feature_extractor_layer,
  layers.Dense(train_data.num_classes)
])

model.summary()

predictions = model(train_image_batch)

predictions.shape

"""### Training the model"""

model.compile(
  optimizer=tf.keras.optimizers.Adam(),
  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),
  metrics=['acc'])

class CollectBatchStats(tf.keras.callbacks.Callback):
  def __init__(self):
    self.batch_losses = []
    self.batch_acc = []

  def on_train_batch_end(self, batch, logs=None):
    self.batch_losses.append(logs['loss'])
    self.batch_acc.append(logs['acc'])
    self.model.reset_metrics()

steps_per_epoch = np.ceil(train_data.samples/train_data.batch_size)

batch_stats_callback = CollectBatchStats()

history = model.fit(train_data, epochs=8,
                    steps_per_epoch=steps_per_epoch,
                    callbacks=[batch_stats_callback])

"""**Display charts for losses and accuracies**"""

plt.figure()
plt.ylabel("Loss")
plt.xlabel("Training Steps")
plt.ylim([0,2])
plt.plot(batch_stats_callback.batch_losses)

plt.figure()
plt.ylabel("Accuracy")
plt.xlabel("Training Steps")
plt.ylim([0,1])
plt.plot(batch_stats_callback.batch_acc)

"""### Check the predictions"""

class_names = sorted(test_data.class_indices.items(), key=lambda pair:pair[1])
class_names = np.array([key.title() for key, value in class_names])
class_names

"""Run the image batch through the model and convert the indices to class names."""

predicted_batch = model.predict(test_image_batch)
predicted_id = np.argmax(predicted_batch, axis=-1)
predicted_label_batch = class_names[predicted_id]

"""**Plotting predictions**"""

label_id = np.argmax(label_batch, axis=-1)

plt.figure(figsize=(10,9))
plt.subplots_adjust(hspace=0.5)
for n in range(30):
  plt.subplot(6,5,n+1)
  plt.imshow(test_image_batch[n])
  color = "green" if predicted_id[n] == label_id[n] else "red"
  plt.title(predicted_label_batch[n].title(), color=color)
  plt.axis('off')
_ = plt.suptitle("Model predictions (green: correct, red: incorrect)")

"""## Random Image Predictions"""

test_human = tf.keras.utils.get_file('image.jpg','https://www.cheatsheet.com/wp-content/uploads/2020/02/Zendaya-2-1024x682.jpg')
test_human = Image.open(test_human).resize(IMAGE_SHAPE)
test_human

# convert img to np array
test_human = np.array(test_human)/255.0
test_human.shape
# call model to make prediction
result = model.predict(test_human[np.newaxis, ...])
predicted_class = np.argmax(result[0], axis=-1)
# predicted_class
predicted_class_name = class_names[predicted_class]
# predicted_class_name

plt.imshow(test_human)
plt.axis('off')
predicted_class_name = class_names[predicted_class]
_ = plt.title("Prediction: " + predicted_class_name.title())

xTest = tf.keras.utils.get_file('image.jpg','https://gamespot1.cbsistatic.com/uploads/scale_landscape/313/3136061/3677918-chrisevans.jpg')

def printPrediction(xTest):
  xTest = Image.open(xTest).resize(IMAGE_SHAPE)
  # convert img to np array
  xTest = np.array(xTest)/255.0
  xTest.shape
  # call model to make prediction
  result = model.predict(xTest[np.newaxis, ...])
  predicted_class = np.argmax(result[0], axis=-1)
  # predicted_class
  predicted_class_name = class_names[predicted_class]
  # predicted_class_name
  plt.imshow(xTest)
  plt.axis('off')
  predicted_class_name = class_names[predicted_class]
  _ = plt.title("Prediction: " + predicted_class_name.title())

printPrediction(xTest)

"""## Export model"""

import time
t = time.time()

export_path = "/content/saved_models/{}".format(int(t))
model.save(export_path, save_format='tf')

export_path

"""Export model to Gdrive"""

t = time.time()

export_path = "/content/drive/My Drive/Models/{}".format(int(t))
model.save(export_path, save_format='tf')

export_path

"""Now confirm that we can reload it, and it still gives the same results:"""

reloaded = tf.keras.models.load_model(export_path)

result_batch = model.predict(test_image_batch)
reloaded_result_batch = reloaded.predict(test_image_batch)

abs(reloaded_result_batch - result_batch).max()

"""This saved model can be loaded for inference later, or converted to [TFLite](https://www.tensorflow.org/lite/convert/) or [TFjs](https://github.com/tensorflow/tfjs-converter).

# Convert to TFLite && quantize the model

No quantization
"""

# Convert the model to the TensorFlow Lite format without quantization
converter = tf.lite.TFLiteConverter.from_keras_model(model)
model_no_quant_tflite = converter.convert()

# # Save the model to disk
f=open('/content/drive/My Drive/Models/TFL/model_no_quant_tflite', "wb")
f.write(model_no_quant_tflite)

"""Dynamic range quanitization"""

# Convert the model to the TensorFlow Lite format without quantization
# converter = tf.lite.TFLiteConverter.from_keras_model(model)
converter.optimizations = [tf.lite.Optimize.DEFAULT]
model_dynamic_quant_tflite = converter.convert()

# # Save the model to disk
f=open('/content/drive/My Drive/Models/TFL/model_dynamic_quant_tflite', "wb")
f.write(model_dynamic_quant_tflite)

"""Full integer Quantization"""

# Convert the model to the TensorFlow Lite format with quantization
def representative_dataset():
  for i in range(500):
    yield([train_data[i].reshape(1, 1)])
# Set the optimization flag.
converter.optimizations = [tf.lite.Optimize.DEFAULT]
# Enforce full-int8 quantization (except inputs/outputs which are always float)
converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]
# Provide a representative dataset to ensure we quantize correctly.
converter.representative_dataset = representative_dataset
model_tflite = converter.convert()

# Save the model to disk
open(MODEL_TFLITE, "wb").write(model_tflite)

"""# Compre Model sizes"""

import os
model_no_quant_size = os.path.getsize('/content/drive/My Drive/Models/TFL/model_no_quant_tflite')
print("Model is %d bytes" % model_no_quant_size)
model_dynamic_quant_size = os.path.getsize('/content/drive/My Drive/Models/TFL/model_dynamic_quant_tflite')
print("Quantized model is %d bytes" % model_dynamic_quant_size)
difference = model_no_quant_size - model_dynamic_quant_size
print("Difference is %d bytes" % difference)